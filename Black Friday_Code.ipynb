{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c54d554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Load the Products Dataset\n",
    "products_df = pd.read_csv('olist_products_dataset.csv')\n",
    "\n",
    "#load the Review and Seller Dataset\n",
    "reviews_df = pd.read_csv('olist_order_reviews_dataset.csv')\n",
    "sellers_df = pd.read_csv('olist_sellers_dataset.csv')\n",
    "\n",
    "# Load the Product Category Name Translation Dataset\n",
    "category_translation_df = pd.read_csv('product_category_name_translation.csv')\n",
    "\n",
    "# Merge the Products Dataset with the Category Translation Dataset on product category name\n",
    "merged_products_df = pd.merge(products_df, category_translation_df, on='product_category_name', how='left')\n",
    "\n",
    "# Load the Orders Dataset\n",
    "orders_df = pd.read_csv('olist_orders_dataset.csv')\n",
    "\n",
    "# Load the Order Items Dataset\n",
    "order_items_df = pd.read_csv('olist_order_items_dataset.csv')\n",
    "\n",
    "# Load the Order Payments Dataset\n",
    "order_payments_df = pd.read_csv('olist_order_payments_dataset.csv')\n",
    "\n",
    "# Merge the Order Items Dataset with the Orders Dataset on order ID\n",
    "merged_order_info_df = pd.merge(order_items_df, orders_df, on='order_id', how='left')\n",
    "\n",
    "# Merge the merged_order_info_df with the Order Payments Dataset on order ID\n",
    "merged_order_info_df = pd.merge(merged_order_info_df, order_payments_df, on='order_id', how='left')\n",
    "\n",
    "# Merge the merged_order_info_df with the merged_products_df on product ID\n",
    "merged_df = pd.merge(merged_order_info_df, merged_products_df, on='product_id', how='left')\n",
    "merged_df = pd.merge(merged_df, sellers_df[['seller_id', 'seller_state']], on='seller_id', how='left')\n",
    "merged_df = pd.merge(merged_df, reviews_df[['order_id', 'review_score']], on='order_id', how='left')\n",
    "\n",
    "# Convert 'order_purchase_timestamp' to datetime format\n",
    "merged_df['order_purchase_timestamp'] = pd.to_datetime(merged_df['order_purchase_timestamp'])\n",
    "\n",
    "# Define Black Friday date range for 2016 and 2017\n",
    "start_date_2016 = '2016-11-18'  # Start date of the week before Black Friday 2016\n",
    "end_date_2016 = '2016-11-25'    # End date of Black Friday 2016\n",
    "start_date_2017 = '2017-11-17'  # Start date of the week before Black Friday 2017\n",
    "end_date_2017 = '2017-11-24'    # End date of Black Friday 2017\n",
    "\n",
    "# Filter transactions for Black Friday deals and the week before Black Friday for both 2016 and 2017\n",
    "black_friday_deals_within_range_df = merged_df[((merged_df['order_purchase_timestamp'].dt.date >= pd.to_datetime(start_date_2016).date()) & \n",
    "                                                (merged_df['order_purchase_timestamp'].dt.date <= pd.to_datetime(end_date_2016).date())) |\n",
    "                                               ((merged_df['order_purchase_timestamp'].dt.date >= pd.to_datetime(start_date_2017).date()) & \n",
    "                                                (merged_df['order_purchase_timestamp'].dt.date <= pd.to_datetime(end_date_2017).date()))]\n",
    "\n",
    "# Display first few rows of the filtered dataframe\n",
    "print(\"Filtered Black Friday Deals Dataset within the specified range:\")\n",
    "print(black_friday_deals_within_range_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddbddab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Rename the filtered Black Friday deals within range dataframe as final_df\n",
    "final_df = black_friday_deals_within_range_df\n",
    "\n",
    "# Data Cleaning and Preprocessing\n",
    "\n",
    "# Handle missing values\n",
    "final_df.dropna(inplace=True)\n",
    "\n",
    "# Assuming 'order_purchase_timestamp' is a column in your DataFrame\n",
    "final_df['order_purchase_timestamp'] = pd.to_datetime(final_df['order_purchase_timestamp'])\n",
    "\n",
    "# Extract year, month, day, hour, and minute components\n",
    "final_df['purchase_year'] = final_df['order_purchase_timestamp'].dt.year\n",
    "final_df['purchase_month'] = final_df['order_purchase_timestamp'].dt.month\n",
    "final_df['purchase_day'] = final_df['order_purchase_timestamp'].dt.day\n",
    "final_df['purchase_hour'] = final_df['order_purchase_timestamp'].dt.hour\n",
    "final_df['purchase_minute'] = final_df['order_purchase_timestamp'].dt.minute\n",
    "\n",
    "# Selecting top 10 variables for predicting the payment value\n",
    "selected_columns = [\n",
    "    'product_category_name_english',\n",
    "    'purchase_year',\n",
    "    'purchase_month',\n",
    "    'purchase_day',\n",
    "    'review_score',\n",
    "    'seller_state'\n",
    "]\n",
    "# Create feature matrix (X) and target variable (y) using the selected columns\n",
    "X = final_df[selected_columns]\n",
    "y = final_df['price']\n",
    "\n",
    "# Further preprocessing steps (handling missing values, encoding categorical variables, etc.) can be performed here\n",
    "# Define a label encoder for the categorical feature\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoder = LabelEncoder()\n",
    "X['product_category_encoded'] = label_encoder.fit_transform(X['product_category_name_english'])\n",
    "X['seller_state_encoded'] = label_encoder.fit_transform(X['seller_state'])\n",
    "\n",
    "# Drop original categorical features\n",
    "X.drop(['product_category_name_english', 'seller_state'], axis=1, inplace=True)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model development\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model's performance on the testing dataset\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbe0571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "joblib.dump(model, 'trained_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
